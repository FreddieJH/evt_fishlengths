---
source---
title: "Statistical methods for estimating the maximum body length of fish species" 
format: 
  html: 
    theme: minty 
    editor: visual 
    execute: 
    echo: false 
    warning: false 
    error: false 
    message: false 
    cache: true
    fig-width: 8
    fig-asp: 0.65
    fig-align: center
    bibliography: references.bib 
---

# Background

```{r}
#| label: pkg-installation
library(tidyverse)
library(evd)
library(patchwork)
library(geomtextpath)
library(multidplyr)
library(parallel)
library(furrr)
library(cmdstanr)
library(data.table)
library(posterior)

```

Extreme Value Theory (EVT) is a branch of statistics that focuses on the extreme deviations from the median of probability distributions. Traditionally, EVT has been applied in fields such as hydrology, finance, and environmental sciences to model and predict rare events, such as floods, market crashes, and extreme weather conditions.

In this analysis, we extend the application of EVT to estimate the maximum lengths of fish species. While previous studies, such as @formacion_extreme_1991, have utilized the Gumbel distribution for this purpose, we aim to incorporate the broader Extreme Value Distribution (EVD) framework. This approach allows for a more comprehensive analysis by considering different types of extreme value distributions, including the Gumbel, FrÃ©chet, and Weibull distributions.

The Generalized Extreme Value (GEV) distribution is defined as:

$$
G(x; \mu, \sigma, \xi) = exp(-[1 + \xi(\frac{x-\mu}{\sigma})]^{-1/\xi})
$$

where:

$\mu$ is the location parameter, $\sigma$ is the scale parameter, $\xi$ is the shape parameter.

By applying the GEV distribution, we can better estimate the maximum lengths of fish species, providing valuable insights for ecological and biological studies.

The Gumbel distribution is a simplified variation of the GEV distribution where $\xi = 0$.

# Understanding GEV

## Shape of GEV

The shape of the GEV distribution is defined by the shape ($\xi$) parameter. Below, location ($\mu$) is fixed at zero, and scale ($\sigma$) is fixed at one.

```{r gev-background}
#| fig-cap: Varying the shape parameter of the Generalised Extreme Value (GEV) distribution. The location and scale parameters are fixed at 0 and 1, respectively.
#| label: fig-GEVshape


tibble(x = seq(-4, 4, by = 0.001)) %>% 
  mutate(shape_0 = dgev(x = x, loc=0, scale=1, shape=0),
         shape_neghalf = dgev(x = x, loc=0, scale=1, shape=-0.5),
         shape_half = dgev(x = x, loc=0, scale=1, shape=0.5)) %>% 
  pivot_longer(cols = contains("shape_")) %>% 
  dplyr::filter(value > 0) %>% 
  ggplot() +
  aes(x = x, y = value, col = name) +
  geom_path(linewidth = 2) +
  labs(x = "x", 
       y = "Density", 
       col = element_blank()) +
  scale_color_discrete(label = c(shape_0 = expression(paste(~xi, " = 0")),
                                 shape_half = expression(paste(~xi, " = 1/2")),
                                 shape_neghalf = expression(paste(~xi, " = -1/2")))) +
  theme_classic(20) +
  theme(legend.position = "inside",
        legend.position.inside = c(1,1), 
        legend.justification = c(1,1))


```

## Simulation of maxima

We can test the GEV distribution with simulated data.

If we take a normal distribution with a mean of 0 and standard deviation of 1, and take a sample of length 1000, and calculate the maximum of this.

```{r norm-max}
#| fig-cap: A sample of length 1000 from a normal distribution with a mean of 0 and standard deviation of 1. The sampled values are indicated as the vertical lines along the x-axis, the maximum of this sample is indicated in red.
#| label: fig-dnorm

sample1000 <- tibble(x = rnorm(1000, mean = 0, sd = 1))

tibble(x = seq(-3.5, 3.5, by = 0.01)) |> 
  mutate(y = dnorm(x, mean = 0, sd = 1)) |> 
  ggplot(aes(x, y)) +
  geom_line() +
  geom_rug(y = 1, 
           data = sample1000 |> filter(x == max(x)), 
           col = "red", linewidth = 2, alpha = 0.8) +
  geom_rug(y = 1, data = sample1000) +
  labs(x = "x", 
       y = "Density") +
  theme_classic(20)

```

Given 100 samples, each of length 1000, from a normal distribution ($\mu$ = 0, $\sigma$ = 1), we take the maxima of those 100 samples and look at the distribution of those 100 maxima. According to theory, they should follow the GEV distribution.

```{r gev-understanding}
#| fig-cap: The distribution of 100 sample maxima, that are derived from 100 samples of length 1000 from a normal distribution with a mean and standard deviation of 0 and 1, respectively.
#| label: fig-maxima-distribution

tibble(sample_number = 1:100) %>%
  expand_grid(sample_id = 1:1000) %>% 
  mutate(x = rnorm(n = 100*1000)) %>% 
  summarise(sample_maxima = max(x), 
            .by = sample_number) %>% 
  ggplot(aes(x = sample_maxima)) +
  geom_density() +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)

```

Since there is variation in the sampling, we can run this many times, each with a new seed, to see how much variation there is.

```{r gev-understanding-multiple}
#| fig-cap: The distribution of 100 sample maxima, repeated 100 times. 
#| label: fig-maxima-distribution-multiple

if(!file.exists("output/simulated_data/rnorm_maxima_10k.csv")){
  for(seed in 1:100){
  
  if(seed == 1) out_tbl <- tibble()
  
  set.seed(seed)
  
  tab <- 
    tibble(sample_number = 1:100) %>%
    expand_grid(sample_id = 1:1000) %>% 
    mutate(x = rnorm(n = 100*1000)) %>% 
    summarise(sample_maxima = max(x), 
              .by = sample_number) %>% 
    mutate(seed = seed)
  
  out_tbl <- 
  bind_rows(
      out_tbl, 
      tab
    )  
  } 
  write_csv(out_tbl, "output/simulated_data/rnorm_maxima_10k.csv")
} else {
  rnorm_maxima_10k <- read_csv("output/simulated_data/rnorm_maxima_10k.csv")
}

rnorm_maxima_10k %>% 
  ggplot(aes(x = sample_maxima, 
             group = seed)) +
  geom_density(colour=alpha("red", 0.3)) +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)

```

## Fitting GEV to simulated maxima

```{r}
#| fig-cap: Fitting 100 GEV distributions to 100 repeats, each of length 100 sample maxima. 
#| label: fig-GEVfitting-multiple

gev_fits <- 
  rnorm_maxima_10k %>% 
  nest(.by = seed) %>% 
  mutate(gev_fit = map(.x = data, 
                       .f = ~evd::fgev(.x$sample_maxima)), 
         loc = map_dbl(.x = gev_fit,
                       .f = ~.x$estimate["loc"]),
         scale = map_dbl(.x = gev_fit,
                         .f = ~.x$estimate["scale"]),
         shape = map_dbl(.x = gev_fit,
                         .f = ~.x$estimate["shape"])) 

median_gev_fits <-
  gev_fits %>% 
  summarise(med_loc = median(loc), 
            med_scale = median(scale), 
            med_shape = median(shape))


median_gev_ests <- 
  tibble(x = seq(min(rnorm_maxima_10k$sample_maxima), 
                 max(rnorm_maxima_10k$sample_maxima), 
                 by = 0.001), 
         y = dgev(x = x, 
                  loc = median_gev_fits$med_loc, 
                  scale = median_gev_fits$med_scale,
                  shape = median_gev_fits$med_shape))

ci_gev_ests <- 
  gev_fits %>% 
  select(seed, loc, scale, shape) %>% 
  expand_grid(x = seq(min(rnorm_maxima_10k$sample_maxima), 
                      max(rnorm_maxima_10k$sample_maxima), 
                      by = 0.001)) %>% 
  rowwise() %>%
  mutate(y = dgev(x = x, 
                  loc = loc, 
                  scale = scale,
                  shape = shape)) %>% 
  ungroup() %>% 
  summarise(
    median = quantile(y, p = 0.5),
    lower = quantile(y, p = 0.025),
    upper = quantile(y, p = 0.975), 
    .by = x
  )

rnorm_maxima_10k %>% 
  ggplot(aes(x = sample_maxima, 
             group = seed)) +
  geom_density(colour=alpha("red", 0.3)) +
  
  geom_ribbon(inherit.aes = FALSE, 
              aes(x = x, ymax = upper, ymin = lower), 
              data = ci_gev_ests, 
              linewidth = 1, 
              alpha = 0.3) +
  geom_line(inherit.aes = FALSE, 
            aes(x = x, y = median), 
            data = ci_gev_ests, 
            linewidth = 1) +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)

```

# Simulating data

```{r}
source("R/")
```

# Estimating maxima (EVT)

The plots show that sample maxima can be well described by the GEV distribution. The following question from this, is how can we use the fitted GEV distribution to estimate the maximum of the underlying distribution.

For this we will use a slightly more realistic example of the underlying 'true' population in relation to fish body lengths.The underlying 'true' distribution of body lengths within a population will be defined by a normal distribution with a mean of 50 (cm) and a standard deviation of 16.67 (one third of 50 - see Heather et al, *in review*).

We will take 10 samples each of mean length 2000 from the underlying population, to get 10 sample maxima to estimate the GEV distribution.

```{r}
#| fig-cap: Estimating maximum length from 10 sample maxima. The sample maxima are calculated from samples of mean length 2000.
#| label: fig-estimate-lmax

single_k = 10
single_lambda = 2000
single_mu = 50

single_output <- 
    sim_tbl_max %>% 
    filter(k == single_k, n_lambda == single_lambda, mu == single_mu, rep == 1) %>% 
    pull(maxima)  %>% 
    .[[1]]

sample_maxima <- single_output$maxima
sample_trueN <- single_output$n

single_gevfit <- suppressWarnings(try(evd::fgev(x = sample_maxima),
    silent = TRUE
))

gev_fun <- function(model_fit, pc_or_q, type = c("qgev", "pgev"), se_factor = 0) {
    type <- match.arg(type)

    gev_loc <- model_fit$estimate["loc"]
    gev_scale <- model_fit$estimate["scale"]
    gev_shape <- model_fit$estimate["shape"]
    gev_loc_se <- model_fit$std.err["loc"]
    gev_scale_se <- model_fit$std.err["scale"]
    gev_shape_se <- model_fit$ std.err["shape"]


    loc <- gev_loc + se_factor * gev_loc_se
    scale <- gev_scale + se_factor * gev_scale_se
    shape <- gev_shape + se_factor * gev_shape_se

    do.call(type, list(pc_or_q, loc, scale, shape))
}

# chosing the percentile based on the number of samples
q_pref <- single_k / (single_k + 1)

p1 <-
    ggplot() +
    geom_textdensity(aes(x),
        data = tibble(x = rnorm(1e6,
            mean = single_mu,
            sd = single_mu*0.34
        )) |> filter(x > 0),
        label = "Underlying body size distribution", hjust = 0.2
    ) +
    geom_rug(aes(x = sample_maxima),
        color = "purple",
        length = unit(0.5, units = "cm")
    ) +
    geom_rect(
        aes(
            xmin = gev_fun(single_gevfit, q_pref, "qgev", -1),
            xmax = gev_fun(single_gevfit, q_pref, "qgev", 1),
            ymin = -Inf,
            ymax = Inf
        ),
        fill = "grey70",
        alpha = 0.3
    ) +
    geom_textvline(aes(xintercept = gev_fun(single_gevfit, q_pref, "qgev")),
        color = "orange",
        linetype = "dashed",
        label = "Estimated LMAX"
    ) +
    labs(
        x = "Fish body length",
        y = "Frequency"
    ) +
    theme_minimal()

p1_lims <- layer_scales(p1)$x$range$range

plot_data <-
    tibble(
        max = sample_maxima,
        rank = rank(sample_maxima),
        pos = rank / (max(rank) + 1),
        n = sample_trueN
    )

p2 <-
    tibble(x = seq(p1_lims[1], p1_lims[2], by = 0.1)) %>%
    mutate(
        pgev = gev_fun(single_gevfit, x, "pgev"),
        pgev_lwr = gev_fun(single_gevfit, x, "pgev", -1),
        pgev_upr = gev_fun(single_gevfit, x, "pgev", 1)
    ) |>
    ggplot() +
    geom_ribbon(aes(x = x, ymin = pgev_lwr, ymax = pgev_upr),
        fill = "grey70", alpha = 0.3
    ) +
    geom_point(aes(x = max, y = pos, size = n),
        color = "purple",
        plot_data
    ) +
    geom_line(aes(x = x, y = pgev)) +
    geom_errorbarh(
        aes(
            xmin = gev_fun(single_gevfit, q_pref, "qgev", -1),
            xmax = gev_fun(single_gevfit, q_pref, "qgev", 1),
            y = q_pref
        ),
        height = 0.03,
        col = "orange",
        lty = "solid",
        data = tibble(n = 1)
    ) +
    geom_vline(
        xintercept = gev_fun(single_gevfit, q_pref, "qgev"),
        col = "orange", lty = "dashed"
    ) +
    labs(
        x = "Fish body length",
        y = "Probability density",
        size = "Sample size"
    ) +
    theme_minimal() +
    theme(
        legend.position = "inside",
        legend.position.inside = c(0.05, 1),
        legend.justification = c(0, 1.2),
        legend.background = element_rect(
            fill = "white",
            color = "black"
        )
    )

p3 <- p1 + p2 + plot_layout(ncol = 1) + plot_annotation(tag_levels = "A")

ggsave(
    plot = p3,
    filename = "output/figures/simulation_evt.png",
    width = 10, height = 10
)

```

The greater the sampling effort, the more likely you are to observe extreme length measures. It is therefore important to account for the sampling effort in the estimation to be clear as to what it is you are estimating. Using 10 sample maxima, each derived from a mean sample size of 2000, we observe the estimated LMAX to be between the 99.9th percentile and the 99.99th percentile. If we have larger sample sizes, it can be expected that this sample size increases.

We can see that increasing the size of the sample by 10-fold, increases the percentile being estimated by a similar 10-fold proportion (e.g. 99th to 99.9th percentile).

```{r}
#| fig-cap: The size of the samples that the maximum is derived is important. The number of samples that you have is also important, but this would be known.
#| label: fig-percentile-estimated

if (!file.exists("output/simulated_data/sim_rnorm_fit_mu50_sd17.csv")) {
    l_mean <- 50 # cm
    l_sd <- l_mean*0.34 # cm

    fit_gev <- function(n_samples, sample_size, l_mean, l_sd) {
        # Generate samples and find the maxima
        sample_maxima <-
            map_dbl(
                .x = 1:n_samples,
                .f = ~ max(rnorm(sample_size, mean = l_mean, sd = l_sd))
            )

        gev_fit <- suppressWarnings(try(evd::fgev(x = sample_maxima), silent = TRUE))

        if (inherits(gev_fit, "try-error")) {
            return(c(loc = 0, scale = 0, shape = 0))
        }

        return(c(
            loc = gev_fit$estimate["loc"],
            scale = gev_fit$estimate["scale"],
            shape = gev_fit$estimate["shape"]
        ))
    }

    n_cores <- parallel::detectCores() - 2
    cluster <- new_cluster(n_cores)
    cluster_library(cluster, "purrr")
    cluster_library(cluster, "evd")
    cluster_copy(cluster, "fit_gev")
    cluster_copy(cluster, "qgev")
    cluster_copy(cluster, "tibble")
    cluster_send(cluster, l_mean <- 50)
    cluster_send(cluster, l_sd <- 16.67)

    sim_rnorm_fit_mu50_sd17 <-
        expand_grid(
            ns = c(10, 20, 50, 100, 200, 500, 1000, 2000),
            ss = c(10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000),
            rep = 1:10
        ) |>
        partition(cluster) |>
        mutate(out = pmap_dfr(
            .l = list(ns = ns, ss = ss),
            .f = function(ns, ss) {
                gev_params <- fit_gev(ns, ss, l_mean = l_mean, l_sd = l_sd)
                tibble(loc = gev_params[1], scale = gev_params[2], shape = gev_params[3])
            }
        )) |>
        collect() |>
        unnest(cols = out)

    write_csv(sim_rnorm_fit_mu50_sd17, "output/simulated_data/sim_rnorm_fit_mu50_sd17.csv")
} else {
    sim_rnorm_fit_mu50_sd17 <- read_csv("output/simulated_data/sim_rnorm_fit_mu50_sd17.csv")
}

sim_rnorm_fit_mu50_sd17 |>
    filter(loc != 0) |>
    rowwise() |>
    mutate(lmax_est = qgev(ns / (ns + 1), loc = loc, scale = scale, shape = shape)) |>
    filter(lmax_est < 50 * 3) |>
    ggplot() +
    aes(x = ss, y = lmax_est, col = as.factor(ns)) +
    geom_point() +
    stat_smooth() +
    geom_texthline(aes(yintercept = yi),
        label = "99th percentile",
        data = tibble(yi = qnorm(0.99, 50, 16.67))
    ) +
    geom_texthline(aes(yintercept = yi),
        label = "99.9th percentile",
        data = tibble(yi = qnorm(0.999, 50, 16.67))
    ) +
    geom_texthline(aes(yintercept = yi),
        label = "99.99th percentile",
        data = tibble(yi = qnorm(0.9999, 50, 16.67))
    ) +
    geom_texthline(aes(yintercept = yi),
        label = "99.999th percentile",
        data = tibble(yi = qnorm(0.99999, 50, 16.67))
    ) +
    scale_x_log10() +
    labs(
        x = "Sample size (log axis)",
        y = "Lmax estimation (cm)",
        col = "# samples"
    ) +
    theme_minimal()

```

## Accounting for sampling effort

It is very difficult to try to estimate the sampling effort. In our case, the sample maxima likely come from various sources (e.g. fishing competitions), that may have very different efforts. What we can do is estimate the maximum length based on some arbitrary number of fishing competitions, e.g. expected maximum to be caught for 100 fishing competitions.

Using the original example of a mean of 50cm and a sd of 17cm.

```{r}
#| fig-cap: The estimated maximum length given 10, 100, or 1000 sampling efforts (e.g. fishing competitions), as indicated by the yellow, red, and blue vertical dashed lines respectively. 
#| label: fig-number-efforts
 
qgev_10comps <- gev_fun(single_gevfit, 1-(1/10), "qgev")
qgev_100comps <- gev_fun(single_gevfit, 1-(1/100), "qgev")
qgev_1000comps <- gev_fun(single_gevfit, 1-(1/1000), "qgev")

tibble(x = seq(80, 150, by = 0.1)) %>% 
  mutate(pgev = gev_fun(single_gevfit, x, "pgev")) %>% 
  ggplot() +
  geom_point(aes(x = max, y = pos), color = "purple",
             plot_data) +
  geom_line(aes(x = x, y = pgev)) +
  geom_vline(xintercept=qgev_10comps, col = "orange", lty = "dashed") +
  geom_vline(xintercept=qgev_100comps, col = "darkred", lty = "dashed") +
  geom_vline(xintercept=qgev_1000comps, col = "navy", lty = "dashed") +
  # geom_vline(xintercept = pc, col = "purple", lty = "dashed") +
  labs(x = "Fish body length",
       y = "Probability") +
  theme_minimal()

```

## Applying EVT to real data (snapper)

Using the evd package to fit our distribution means that we can extract the standard error in the estimates of the three parameters.

```{r}
# a and b values from fishbase with highest R2 value
# https://fishbase.se/popdyn/FishLWSummary.php?ID=6426&id2=43704&genusname=Pagrus&speciesname=auratus&fc=330&variable_Length=10&gm_a=0.03840258163471&gm_b=2.7759517453138

# kg2cm <- function(w, a = 0.01, b = 3) ((w * 1000) / a)^(1 / b) # basic formula
kg2cm <- function(w, a = 0.04478, b = 2.673) ((w * 1000) / a)^(1 / b)

snapper_maxima <- tibble(
    type = c(
        rep("length", 8),
        rep("weight", 4)
    ),
    max = c(
        91.3, 102, 112, 107, 107, 99.2, 95, 82.2,
        kg2cm(c(11.8, 18.4, 16.5, 17.2))
    )
)

q_100comps <- 1 - (1 / 100)

snapper_gev_fit <- suppressWarnings(try(evd::fgev(x = snapper_maxima$max),
    silent = TRUE
))

plot_data <-
    snapper_maxima %>% 
    mutate(
        max,
        rank = rank(max),
        pos = rank / (max(rank) + 1)
    )


add_line <- function(val, val2, lty) {
    geom_textsegment(
        y = -Inf,
        yend = val2,
        x = val,
        xend = val,
        lty = lty,
        label = paste0(round(val), "cm"),
        hjust = 0.1,
        col = "darkred",
        lty = "dashed",
        data = tibble(n = 1)
    )
}

lmax_100comps <- gev_fun(snapper_gev_fit, q_100comps, "qgev")
lmax_100comps_lwr <- gev_fun(snapper_gev_fit, q_100comps, "qgev", -1)
lmax_100comps_upr <- gev_fun(snapper_gev_fit, q_100comps, "qgev", 1)

tibble(x = seq(min(snapper_maxima$max) * 0.8, max(snapper_maxima$max) * 1.3, by = 0.1)) %>%
    mutate(
        pgev = gev_fun(snapper_gev_fit, x, "pgev"),
        pgev_lwr = gev_fun(snapper_gev_fit, x, "pgev", -1),
        pgev_upr = gev_fun(snapper_gev_fit, x, "pgev", 1)
    ) %>%
    ggplot() +
    geom_ribbon(aes(x = x, ymin = pgev_lwr, ymax = pgev_upr),
        fill = "grey70", alpha = 0.3
    ) +
    geom_point(aes(x = max, y = pos, pch = type),
        color = "purple",
        plot_data
    ) +
    geom_line(aes(x = x, y = pgev)) +
    add_line(lmax_100comps, q_100comps, 1) +
    add_line(lmax_100comps_lwr, q_100comps, 2) +
    add_line(lmax_100comps_upr, q_100comps, 2) +
    geom_textsegment(
        x = -Inf, xend = lmax_100comps_upr,
        y = q_100comps, yend = q_100comps,
        col = "darkred",
        label = "if number of samples = 100",
        data = tibble(n = 1),
        hjust = 0.1
    ) +
    annotate("text",
        x = -Inf,
        y = 0.9,
        family = "Fira mono",
        label = sprintf(
            "Î¼ = %-6.1f\nÏ = %-6.1f\nÎ¾ = %-6.3f",
            snapper_gev_fit$estimate["loc"],
            snapper_gev_fit$estimate["scale"],
            snapper_gev_fit$estimate["shape"]
        ),
        size = 6,
        hjust = -0.5, vjust = 1
    ) +
    labs(
        x = "Fish body length (cm)",
        y = "Probability"
    ) +
    theme_minimal()

```

# Numerical estimation of $L_{max}$

```{r}

mod <- cmdstan_model("models/max_est.stan", stanc_options = list("O1"))

# Stan fitting function
fit_stan_model <- function(rep, k, lambda, mu, maxima) {
    fit <- mod$sample(
        data = list(k = length(maxima), x = maxima),
        iter_warmup = 1000,
        iter_sampling = 1000,
        chains = 4,
        parallel_chains = 4,
        refresh = 500
    )

    filename <-
        paste0(
            "rep", rep,
            "_k", k,
            "_lambda", lambda,
            "_mu", mu
        )

    est_max_tbl <-
        fit$draws(format = "df") |>
        select(mu, sigma, lambda) |>
        mutate(est_max = mu + sigma * qnorm(lambda / (lambda + 1)))

    data.table::fwrite(fit$summary(), file = paste0("stan_outputs/", filename, ".csv"))
    data.table::fwrite(est_max_tbl, file = paste0("max_posterior/", filename, ".csv"))

    return(NULL)
}

processed_files <-
    list.files(
        "models/output_data/stan_outputs",
        full.names = FALSE
    ) %>%
    str_remove(".csv")

unprocessed_tbl <-
    sim_tbl_max |>
    filter(!filename %in% processed_files)

if(nrow(unprocessed_tbl)){
    plan(multisession)
    future_pmap(
        .l = list(
            rep = unprocessed_tbl$rep,
            k = unprocessed_tbl$k,
            lambda = unprocessed_tbl$n_lambda,
            mu = unprocessed_tbl$mu,
            maxima = unprocessed_tbl$maxima
        ),
        .f = fit_stan_model,
        .options = furrr_options(seed = TRUE),
        .progress = TRUE
    )
    plan(sequential)
}

combine_stan_results <- function() {
    filename_pattern <- "rep[0-9]+_k[0-9]+_lambda[0-9]+_mu[0-9]+"
    vroom::vroom(
        list.files("models/output_data/stan_outputs",
            pattern = filename_pattern,
            full.names = TRUE
        ),
        id = "filename",
        num_threads = parallel::detectCores() - 2
    ) %>%
        mutate(filename = str_extract(filename, filename_pattern)) %>%
        left_join(sim_tbl) %>%
        fwrite(file = "output/data/stan_output2.csv")
}

if(file.exists("output/data/stan_output.csv")) {
    saved_files <-
        vroom::vroom("output/data/stan_output.csv") %>%
        pull(filename) %>%
        unique() %>%
        str_remove(".csv")

    unsaved_files <-
        sim_tbl_max %>%
        filter(!filename %in% saved_files) %>%
        pull(filename)

    if (length(unsaved_files)) {
        combine_stan_results()
    }
} else {
    combine_stan_results()
}

sim_output <- vroom::vroom("output/data/stan_output2.csv")


```

The method appears to estimate the maximum length well, even if it does not estimate the exact value of the underlying distribution perfectly. This makes sense, considering a large fish may be caught either if the population has a large mean size, or if the sample size is large with a relatively smaller mean body size.

```{r}
#| fig-cap: The size of the samples that the maximum is derived is important. The number of samples that you have is also important, but this would be known.
#| label: fig-percentile-estimated

find_max_x <- function(mu, sigma, n) {
    optimize(function(x) calc_max(x, n, mu, sigma),
        interval = c(mu - 5 * sigma, mu + 5 * sigma),
        maximum = TRUE
    )$maximum
}

calc_max <- function(x, n, mu, sigma) {
    fx <- dnorm(x, mu, sigma)
    Fx <- pnorm(x, mu, sigma)
    max <- (n * (Fx^(n - 1))) * fx
    return(max)
}

calculated_lmax <-
    sim_tbl %>%
    mutate(calc_max = pmap_dbl(
        .l = list(
            mu = mu,
            sigma = sigma,
            n = n_lambda
        ),
        .f = find_max_x
    ))

estimated_lmax <-
    sim_output |>
    filter(!str_detect(variable, "max_vals")) %>%
    select(filename, variable, median) %>%
    pivot_wider(
        names_from = variable,
        values_from = median,
        names_prefix = "est_"
    ) %>%
    mutate(est_max = pmap_dbl(
        .l = list(
            mu = est_mu,
            sigma = est_sigma,
            n = est_lambda
        ),
        .f = find_max_x
    )) %>%
    select(filename, est_max)


calculated_lmax %>%
    left_join(estimated_lmax) %>%
    ggplot(aes(est_max, calc_max,
        col = as.factor(mu),
        size = as.factor(n_lambda)
    )) +
    geom_point(alpha = 0.05) +
    geom_abline(slope = 1) +
    labs(
        x = "Estimated maximum length (cm)",
        y = "Calculated maximum length (cm)",
        col = "True mu",
        size = "True lambda"
    ) +
    theme_classic(20) +
    guides(
        color = guide_legend(override.aes = list(alpha = 1)),
        size = guide_legend(override.aes = list(alpha = 1))
    )


ggsave("output/figures/estimated_vs_calculated_lmax.png",
    width = 10, height = 7
        
```

## Numerical estimation - real data

```{r}

mod <- cmdstan_model("models/max_est.stan", stanc_options = list("O1"))

snapper_fit <- mod$sample(
    data = list(
        k = length(snapper_maxima$max),
        x = snapper_maxima$max
    ),
    iter_warmup = 1000,
    iter_sampling = 2000,
    chains = 4,
    parallel_chains = 4,
    refresh = 500,
    save_warmup = TRUE
)

snapper_fit_summary <-
    snapper_fit |>
    posterior::summarise_draws()

snapper_fit %>%
    as_draws_df() %>%
    mutate(est_max = pmap_dbl(
        .l = list(
            mu = mu,
            sigma = sigma,
            n = lambda
        ),
        .f = find_max_x
    )) %>%
    reframe(
        median_max = median(est_max),
        sd = sd(est_max)
    )

snapper_fit %>%
    as_draws_df() %>%
    as_tibble() %>%
    select(mu, sigma, lambda, .draw, .iteration, .chain) %>%
    mutate(est_max = pmap_dbl(
        .l = list(
            mu = mu,
            sigma = sigma,
            n = lambda
        ),
        .f = find_max_x
    )) %>%
    ggplot(aes(est_max)) +
    geom_density()


snapper_estimates <-
    snapper_fit %>%
    as_draws_df() %>%
    as_tibble() %>%
    select(mu, sigma, lambda, .draw, .iteration, .chain) %>%
    expand_grid(size = 0:200) %>%
    mutate(pdf = calc_max(size, n = lambda, mu = mu, sigma = sigma)) %>%
    mutate(cdf = cumsum(pdf), .by = c(.chain, .draw)) %>%
    reframe(
        max_fit = mean(cdf),
        max_lwr = quantile(cdf, 0.025),
        max_upr = quantile(cdf, 0.975),
        .by = size
    )

snapper_estimates %>%
    ggplot(aes(size, max_fit)) +
    geom_ribbon(aes(ymin = max_lwr, ymax = max_upr),
        fill = "grey70",
        alpha = 0.8
    ) +
    geom_line() +
    scale_x_continuous(label = scales::label_number(suffix = "cm")) +
    theme_classic(20) +
    geom_rug(aes(x = maxima),
        data = tibble(maxima = snapper_maxima$max),
        col = "purple",
        inherit.aes = FALSE
    ) +
    labs(
        x = "Body length, x",
        y = "Pr(x > Lmax)"
    )

ggsave("output/figures/snapper_numerical_est.png",
    width = 10, height = 7
)

```

# Comparing two methods

```{r}
snapper_fit %>%
    as_draws_df() %>%
    as_tibble() %>%
    select(mu, sigma, lambda, .draw, .iteration, .chain) %>%
    expand_grid(size = 50:200) %>%
    mutate(pdf = calc_max(size, n = lambda, mu = mu, sigma = sigma)) %>%
    mutate(cdf = cumsum(pdf), .by = c(.chain, .draw)) %>%
    arrange(desc(cdf))

estimate_lmax_evt <- function(maxima, ngrid = 1000) {
    gev_fit <- suppressWarnings(try(evd::fgev(x = maxima), silent = TRUE))

    start_grid <- 0.5 * min(maxima)
    end_grid <- 1.5 * max(maxima)

    tibble(x = seq(start_grid, end_grid, length.out = ngrid)) %>%
        mutate(
            pgev_fit = gev_fun(gev_fit, x, "pgev"),
            pgev_lwr = gev_fun(gev_fit, x, "pgev", -1),
            pgev_upr = gev_fun(gev_fit, x, "pgev", 1)
        )
}

estimate_lmax_numerical <- function(maxima, ngrid = 1000, model_filename = "models/max_est.stan") {

    mod <- cmdstan_model(model_filename, stanc_options = list("O1"))
    stan_model_fit <- mod$sample(
        data = list(
            k = length(maxima),
            x = maxima
        ),
        iter_warmup = 1000,
        iter_sampling = 2000,
        chains = 4,
        parallel_chains = 4,
        refresh = 500,
        save_warmup = TRUE
    )

    snapper_fit %>%
        as_draws_df() %>%
        as_tibble() %>%
        select(!contains("max_vals")) %>%
        select(mu, sigma, lambda, .draw, .iteration, .chain) %>%
        expand_grid(size = 0:300) %>%
        mutate(pdf = calc_max(size, n = lambda, mu = mu, sigma = sigma)) %>%
        mutate(cdf = cumsum(pdf), .by = c(.chain, .draw)) %>%
        arrange(desc(cdf))

    start_grid <- 0.5 * min(maxima)
    end_grid <- 1.5 * max(maxima)
    step_size <- (end_grid - start_grid) / (ngrid - 1)

    stan_model_fit %>%
        posterior::as_draws_df() %>%
        as_tibble() %>%
        select(mu, sigma, lambda, .draw, .iteration, .chain) %>%
        expand_grid(x = seq(start_grid, end_grid, length.out = ngrid)) %>%
        mutate(pdf = calc_max(x, n = lambda, mu = mu, sigma = sigma)) %>%
        mutate(cdf = cumsum(pdf) * step_size, .by = c(.chain, .draw)) %>%
        reframe(
            pmax_fit = mean(cdf),
            pmax_lwr = quantile(cdf, 0.025),
            pmax_upr = quantile(cdf, 0.975),
            .by = x
        )
}

est1 <- estimate_lmax_evt(snapper_maxima$max)
est2 <- estimate_lmax_numerical(snapper_maxima$max)


est1 %>%
    left_join(est2) %>%
    pivot_longer(
        cols = -x,
        names_to = c("model", ".value"),
        names_pattern = "(pgev|pmax)_(.*)"
    ) %>%
    mutate(model_clean = case_when(model == "pgev" ~ "EVT", 
    model == "pmax" ~ "Numerical estimation"
    )) %>% 
    ggplot(aes(x, y = fit, col = model_clean)) +
    geom_line() +
    geom_ribbon(
        aes(
            ymin = lwr,
            ymax = upr, fill = model_clean
        ),
        alpha = 0.1
    ) +
    geom_rug(aes(x = maxima),
        inherit.aes = FALSE,
        data = tibble(maxima = snapper_maxima$max)
    ) +
    scale_x_continuous(label = scales::label_number(suffix = "cm")) +
    labs(x = "Body size", 
    y = "Pr(x>Lmax)") +
    theme_classic(20) +
    theme(
        legend.position = "inside",
        legend.position.inside = c(0, 1),
        legend.justification = c(-0.1, 1.5), 
        legend.title=element_blank()
        )
    
ggsave("output/figures/snapper_maxlength_estimation.png",
    width = 10, height = 7
)

```

# Chosing a percentile

```{r}
snapper_fit
snapper_gev_fit <- suppressWarnings(try(evd::fgev(x = snapper_maxima$max),
    silent = TRUE
))


```

```{r}
library(ggplot2)

# Create a sample data frame
data <- data.frame(
  x = rnorm(100),
  y = rnorm(100)
)

# Create a scatter plot
ggplot(data, aes(x = x, y = y)) +
  geom_point() +
  labs(
    title = "Scatter Plot",
    x = "X-axis Label",
    y = "Y-axis Label"
  ) +
  theme_minimal() + 
  
```