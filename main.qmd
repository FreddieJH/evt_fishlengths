---
title: "Improvements on the application of extreme value theory on estimating the maximum length of fishes"
format: 
  html:
    theme: minty
editor: visual
execute:
  echo: false
  warning: false
  error: false
  message: false
bibliography: references.bib
---

```{r packages}
library(tidyverse)
library(evd)
library(patchwork)
library(geomtextpath)
library(multidplyr)
library(parallel)
```

# Background

Extreme Value Theory (EVT) is a branch of statistics that focuses on the extreme deviations from the median of probability distributions. Traditionally, EVT has been applied in fields such as hydrology, finance, and environmental sciences to model and predict rare events, such as floods, market crashes, and extreme weather conditions.

In this analysis, we extend the application of EVT to estimate the maximum lengths of fish species. While previous studies, such as @formacion1991, have utilized the Gumbel distribution for this purpose, we aim to incorporate the broader Extreme Value Distribution (EVD) framework. This approach allows for a more comprehensive analysis by considering different types of extreme value distributions, including the Gumbel, FrÃ©chet, and Weibull distributions.

The Generalized Extreme Value (GEV) distribution is defined as:

$$
G(x; \mu, \sigma, \xi) = exp(-[1 + \xi(\frac{x-\mu}{\sigma})]^{-1/\xi})
$$

where:

$\mu$ is the location parameter, $\sigma$ is the scale parameter, $\xi$ is the shape parameter.

By applying the GEV distribution, we can better estimate the maximum lengths of fish species, providing valuable insights for ecological and biological studies.

The Gumbel distribution is a simplified variation of the GEV distribution where $\xi = 0$.

# GEV

## Shape of GEV

The shape of the GEV distribution is defined by the shape ($\xi$) parameter. Below, location ($\mu$) is fixed at zero, and scale ($\sigma$) is fixed at one.

```{r gev-background}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: Varying the shape parameter of the Generalised Extreme Value (GEV) distribution. The location and scale parameters are fixed at 0 and 1, respectively.
#| label: fig-GEVshape


tibble(x = seq(-4, 4, by = 0.001)) %>% 
  mutate(shape_0 = dgev(x = x, loc=0, scale=1, shape=0),
         shape_neghalf = dgev(x = x, loc=0, scale=1, shape=-0.5),
         shape_half = dgev(x = x, loc=0, scale=1, shape=0.5)) %>% 
  pivot_longer(cols = contains("shape_")) %>% 
  filter(value > 0) %>% 
  ggplot() +
  aes(x = x, y = value, col = name) +
  geom_path() +
  labs(x = "x", 
       y = "Density", 
       col = element_blank()) +
  scale_color_discrete(label = c(shape_0 = expression(paste(~xi, " = 0")),
                                 shape_half = expression(paste(~xi, " = 1/2")),
                                 shape_neghalf = expression(paste(~xi, " = -1/2")))) +
  theme_classic(20) +
  theme(legend.position = "inside",
        legend.position.inside = c(1,1), 
        legend.justification = c(1,1))

```

## Understanding GEV

We can test the GEV distribution with simulated data.

If we take a normal distribution with a mean of 0 and standard deviation of 1, and take a sample of length 1000, and calculate the maximum of this.

```{r norm-max}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: A sample of length 1000 from a normal distribution with a mean of 0 and standard deviation of 1. The sampled values are indicated as the vertical lines along the x-axis, the maximum of this sample is indicated in red.
#| label: fig-dnorm

sample1000 <- tibble(x = rnorm(1000, mean = 0, sd = 1))

tibble(x = seq(-3.5, 3.5, by = 0.01)) |> 
  mutate(y = dnorm(x, mean = 0, sd = 1)) |> 
  ggplot(aes(x, y)) +
  geom_line() +
  geom_rug(y = 1, data = sample1000 |> filter(x == max(x)), col = "red", linewidth = 2, alpha = 0.8) +
  geom_rug(y = 1, data = sample1000) +
  labs(x = "x", 
       y = "Density") +
  theme_classic(20)


```

Given 100 samples, each of length 1000, from a normal distribution ($\mu$ = 0, $\sigma$ = 1), we take the maxima of those samples and look at the distribution of those 100 maxima. According to theory, they should follow the GEV distribution.

```{r gev-understanding}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: The distribution of 100 sample maxima, that are derived from 100 samples of length 1000 from a normal distribution with a mean and standard deviation of 0 and 1, respectively.
#| label: fig-maxima-distribution

tibble(sample_number = 1:100) %>%
  expand_grid(sample_id = 1:1000) %>% 
  mutate(x = rnorm(n = 100*1000)) %>% 
  summarise(sample_maxima = max(x), 
            .by = sample_number) %>% 
  ggplot(aes(x = sample_maxima)) +
  geom_density() +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)


```

Since there is variation in the sampling, we can run this multiple times, each with a new seed, to see how much variation there is.

```{r gev-understanding-multiple}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: The distribution of 100 sample maxima, repeated 100 times. 
#| label: fig-maxima-distribution-multiple

for(seed in 1:100){
  
  if(seed == 1) out_tab <- tibble()
  
  set.seed(seed)
  
  tab <- 
    tibble(sample_number = 1:100) %>%
    expand_grid(sample_id = 1:1000) %>% 
    mutate(x = rnorm(n = 100*1000)) %>% 
    summarise(sample_maxima = max(x), 
              .by = sample_number) %>% 
    mutate(seed = seed)
  
  out_tab <- 
    bind_rows(
      out_tab, 
      tab
    )
  
}

out_tab %>% 
  ggplot(aes(x = sample_maxima, 
             group = seed)) +
  geom_density(colour=alpha("red", 0.3)) +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)


```

## Fitting GEV to simulated maxima

```{r}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: Fitting 100 GEV distributions to 100 repeats, each of length 100 sample maxima. 
#| label: fig-GEVfitting-multiple

gev_fits <- 
  out_tab %>% 
  nest(.by = seed) %>% 
  mutate(gev_fit = map(.x = data, 
                       .f = ~evd::fgev(.x$sample_maxima)), 
         loc = map_dbl(.x = gev_fit,
                       .f = ~.x$estimate["loc"]),
         scale = map_dbl(.x = gev_fit,
                         .f = ~.x$estimate["scale"]),
         shape = map_dbl(.x = gev_fit,
                         .f = ~.x$estimate["shape"])) 

median_gev_fits <-
  gev_fits %>% 
  summarise(med_loc = median(loc), 
            med_scale = median(scale), 
            med_shape = median(shape))


median_gev_ests <- 
  tibble(x = seq(min(out_tab$sample_maxima), 
                 max(out_tab$sample_maxima), 
                 by = 0.001), 
         y = dgev(x = x, 
                  loc = median_gev_fits$med_loc, 
                  scale = median_gev_fits$med_scale,
                  shape = median_gev_fits$med_shape))

ci_gev_ests <- 
  gev_fits %>% 
  select(seed, loc, scale, shape) %>% 
  expand_grid(x = seq(min(out_tab$sample_maxima), 
                      max(out_tab$sample_maxima), 
                      by = 0.001)) %>% 
  rowwise() %>%
  mutate(y = dgev(x = x, 
                  loc = loc, 
                  scale = scale,
                  shape = shape)) %>% 
  ungroup() %>% 
  summarise(
    median = quantile(y, p = 0.5),
    lower = quantile(y, p = 0.025),
    upper = quantile(y, p = 0.975), 
    .by = x
  )



out_tab %>% 
  ggplot(aes(x = sample_maxima, 
             group = seed)) +
  geom_density(colour=alpha("red", 0.3)) +
  
  geom_ribbon(inherit.aes = FALSE, 
              aes(x = x, ymax = upper, ymin = lower), 
              data = ci_gev_ests, 
              linewidth = 1, 
              alpha = 0.3) +
  geom_line(inherit.aes = FALSE, 
            aes(x = x, y = median), 
            data = ci_gev_ests, 
            linewidth = 1) +
  labs(x = "Sample maximum", 
       y = "Density") +
  theme_classic(20)

```

# Estimating maxima

The plots show that sample maxima can be well described by the GEV distribution. The following question from this, is how can we use the fitted GEV distribution to estimate the maximum of the underlying distribution.

For this we will use a slightly more realistic example of the underlying 'true' population in relation to fish body lengths.

The underlying 'true' distribution of body lengths within a population will be defined by a normal distribution with a mean of 50 (cm) and a standard deviation of 16.67 (= one third of 50).

We will take 10 samples each of length 1000 from the underlying population, to get 10 sample maxima to estimate the GEV distribution.

```{r}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: Estimating maximum length from 10 sample maxima. The sample maxima are calculated from samples of length 1000. 
#| label: fig-estimate-lmax

l_mean <- 50 #cm
l_sd <- 16.67 #cm
n_samples <- 10
sample_size <- 1000

for(s in 1:n_samples){
  if(s == 1) sample_maxima <- c()
  sample <- rnorm(sample_size, mean = l_mean, sd = l_sd)
  sample_maxima[s] <- max(sample)
}

gev_fit <- suppressWarnings(try(evd::fgev(x = sample_maxima),
                                    silent = TRUE))

gev_loc <- gev_fit$estimate["loc"]
gev_scale <- gev_fit$estimate["scale"]
gev_shape <- gev_fit$estimate["shape"]
qgev_est <- function(pc) qgev(pc, gev_loc, gev_scale, gev_shape) 


qnorm_99 <- qnorm(0.9900, mean = l_mean, sd = l_sd)
qnorm_999 <- qnorm(0.9990, mean = l_mean, sd = l_sd)
qnorm_9999 <- qnorm(0.9999, mean = l_mean, sd = l_sd)
qnorm_99999 <- qnorm(0.99999, mean = l_mean, sd = l_sd)
qgev_99 <- qgev_est(0.99) 
qgev_better <- qgev_est(n_samples/(n_samples+1))


p1 <- 
  ggplot() +
      geom_textdensity(aes(x), data = tibble(x = rnorm(1e6, 
                                                   mean = l_mean, 
                                                   sd = l_sd)) |> filter(x > 0), 
                       label = "Underlying body size distribution", hjust = 0.2) +
      geom_rug(aes(x = sample_maxima), 
               color = "purple", 
               length = unit(0.5, units = "cm")) +
          geom_textvline(
            xintercept = qnorm_99,
            color = "orange", 
            linetype = "dashed", 
            label = "99th percentile") +
              geom_textvline(
            xintercept = qnorm_999,
            color = "blue", 
            linetype = "dashed", 
            label = "99.9th percentile") +
                  geom_textvline(
            xintercept = qnorm_9999,
            color = "darkred", 
            linetype = "dashed", 
            label = "99.99th percentile") +
                    geom_textvline(
            xintercept = qnorm_99999,
            color = "black", 
            linetype = "dashed", 
            label = "99.999th percentile") +
    geom_textvline(aes(xintercept = qgev_better), 
                   color = "purple", 
                   linetype = "dashed", 
                   label = "Estimated LMAX") +
    labs(x = "Fish body length",
         y = "Frequency") +
    theme_minimal()

p1_lims <- layer_scales(p1)$x$range$range

plot_data <-
      tibble(max = sample_maxima, 
             rank = rank(sample_maxima), 
             pos = rank/(max(rank)+1)) 

  p2 <-
      tibble(x = seq(p1_lims[1], p1_lims[2], by = 0.1)) %>% 
      mutate(pgev = pgev(q = x, 
                         loc = gev_loc, 
                         scale = gev_scale,
                         shape = gev_shape)) %>% 
      ggplot() +
      geom_point(aes(x = max, y = pos), color = "purple",
                 plot_data) +
      geom_line(aes(x = x, y = pgev)) +
      geom_vline(xintercept = qgev_better, col = "purple", lty = "dashed") +
     labs(x = "Fish body length",
         y = "Probability density") +
      theme_minimal()
    
    
p1+p2 + plot_layout(ncol = 1)
    
```

In this simple case the estimated maximum length is determined by the sampling effort. The greater the sampling effort, the more likely you are to observe extreme length measures. It is therefore important to account for the sampling effort in the estimation to be clear as to what it is you are estimating. Using 10 sample maxima, each derived from a sample size of 1000, we observe the estimated LMAX to be between the 99.9th percentile and the 99.99th percentile. If we have larger sample sizes, it can be expected that this sample size increases.

We can see that increasing the size of the sample by 10-fold, increases the percentile being estimated by a similar 10-fold proportion (e.g. 99th to 99.9th percentile).

```{r}
#| fig-width: 8
#| fig-asp: 0.65
#| fig-align: center
#| fig-cap: The size of the samples that the maximum is derived is important. The number of samples that you have is also important, but this would be known.
#| label: fig-percentile-estimated

l_mean <- 50 #cm
l_sd <- 16.67 #cm

fit_gev <- function(n_samples, sample_size, l_mean, l_sd) {
  
  # Generate samples and find the maxima
  sample_maxima <- map_dbl(1:n_samples, ~max(rnorm(sample_size, mean = l_mean, sd = l_sd)))
  
  gev_fit <- suppressWarnings(try(evd::fgev(x = sample_maxima), silent = TRUE))
  
  if (inherits(gev_fit, "try-error")) {
    return(c(loc = 0, scale = 0, shape = 0))
  }
  
  return(c(loc = gev_fit$estimate["loc"], scale = gev_fit$estimate["scale"], shape = gev_fit$estimate["shape"]))
}

n_cores <- parallel::detectCores() - 2
cluster <- new_cluster(n_cores)
cluster_library(cluster, "purrr")
cluster_library(cluster, "evd")
cluster_copy(cluster, "fit_gev")
cluster_copy(cluster, "qgev")
cluster_copy(cluster, "tibble")
cluster_send(cluster, l_mean <-  50)
cluster_send(cluster, l_sd <-  16.67)

sim_output <- 
  expand_grid(ns = c(10, 20, 50, 100, 200, 500, 1000, 2000), 
            ss = c(10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000), 
            rep = 1:10) |> 
  partition(cluster) |>
  mutate(out = pmap_dfr(.l = list(ns = ns, ss = ss), 
                        .f = function(ns, ss) {
    gev_params <- fit_gev(ns, ss, l_mean = l_mean, l_sd = l_sd) 
    tibble(loc = gev_params[1], scale = gev_params[2], shape = gev_params[3])
  })) |> 
  collect() |> 
  unnest(cols = out)

sim_output |> 
  filter(loc != 0) |> 
  rowwise() |> 
  mutate(lmax_est = qgev(ns/(ns+1), loc = loc, scale = scale, shape = shape)) |>
  filter(lmax_est < l_mean*3) |> 
  ggplot() +
  aes(x = ss, y = lmax_est, col = as.factor(ns)) +
  geom_point() + 
  stat_smooth() +
  geom_texthline(aes(yintercept = yi), label = "99th percentile", data = tibble(yi = qnorm_99)) +
  geom_texthline(aes(yintercept = yi), label = "99.9th percentile", data = tibble(yi = qnorm_999)) +
  geom_texthline(aes(yintercept = yi), label = "99.99th percentile", data = tibble(yi = qnorm_9999)) +
  geom_texthline(aes(yintercept = yi), label = "99.999th percentile", data = tibble(yi = qnorm_99999)) +
  scale_x_log10() +
  labs(x = "Sample size (log axis)", 
       y = "Lmax estimation (cm)", 
       col = "# samples") +
  theme_minimal()


```

## Accounting for sampling effort

It is very difficult to try to estimate the sampling effort. In our case, the sample maxima likely come from various sources (e.g. fishing competitions), that may have very different efforts. What we can do is estimate the maximum length based on some arbitrary number of fishing competitions, e.g. expected maximum to be caught for 100 fishing competitions.

```{r}

qgev_10comps <- qgev_est(10/(10+1))
qgev_100comps <- qgev_est(100/(100+1))
qgev_1000comps <- qgev_est(1000/(1000+1))

tibble(x = seq(80, 120, by = 0.1)) %>% 
  mutate(pgev = pgev(q = x, 
                     loc = gev_loc, 
                     scale = gev_scale,
                     shape = gev_shape)) %>% 
  ggplot() +
  geom_point(aes(x = max, y = pos), color = "purple",
             plot_data) +
  geom_line(aes(x = x, y = pgev)) +
  geom_vline(xintercept=qgev_10comps, col = "orange", lty = "dashed") +
  geom_vline(xintercept=qgev_100comps, col = "darkred", lty = "dashed") +
  geom_vline(xintercept=qgev_1000comps, col = "navy", lty = "dashed") +
  # geom_vline(xintercept = qgev_better, col = "purple", lty = "dashed") +
  labs(x = "Fish body length",
       y = "Probability density") +
  theme_minimal()

```
